# AI Systems Workshop 2017

## Eric Xing

Data-parallel proximal gradient under SSP

in the past, BSP model

A statle synchronous parallel bridgiing model

Parameter server architecture
 - Bosen

SSP data parallel convergence theorem

SSP Data parallel, Async performance

System / Algorithm codesign

Matrix parameterized models

Big MPMs

Need to send paralllel worker updates to other machines
 Primal SGC
 Stochastic dual coordinate ascent

A computing communication tradeoff

 Full update
 pre-update

Why is SFB faster?
 Faster than PS and Spark

Topologies to use

Paramster storage and communication paradigms

Synchonization of a paramter machines

How t o reduce traffic in P2P
  random partial broadcasting

Hybrid updates: PS + SFB
 Example : CNN

 How to distribute?
 How to communicate?


## Paul Barham

Programming model
Hardware paltforms
Model architectures
machine learning inside the system

Use machine learning to improve machine learning system itself

Tensorflow: distributed dataflow ()with state)

Programming model evolution

Note to system people: faster isnt always better

Eager graphs and compilation ....
 Eager execution: increased interactivity
 graph model: flexible distributed computation
 JIT compiler: acceleration of important subgraphs
 Ahead of time compilation: generate standalone binaries

A few trends in the kinds of mdoels we want to train

deepmind wavenet

recurrent sequence model

very large language models needing model parallelism

Bigger model, but sparsely activated 

huge model capacity for large

strucutre for the model: repeated structure

For large models, model parallelism is important

Using reinforcement learning to imporve system performance

replace complex heuristics with leared strategies
 compiler optimzations
 placement of operators on devices

Device placement with reinforcement learning

Using reinforcement learning to design the model

Current solution = data + computation + ML experties
Can we turn this into solution = date + 100x computation

Idea : model-generating model trained via RL (ICLR 2017)
  generate ten models
  train them on the same problem for a fixed time

Conclusions
 After 30 uears and 10^5 x compute neural networks alaready outperform hunmans on many tasks
 Machine learning systems are rapidly evolving
   researchers driving changes to programmingmodel
   exciting hardware

## Joseph Gonzalez

Research at the interaction of AI and systems

Look back:
 Scaling to large datasets
 Using machine learning to solve problems in system
 Big learning

 support lowlatency high through put serving workloads

 models getting more complex
 10x of Gflops
 recurrentnets

 deployed on critical path

 hardware in the train domain



## Tianqi Chen

Layout transormation
Quantization
operator kernal optimzation
benchmarking

need optimzed hardware kernel for each variable and each hardware 

One problem to solve, to bridge frontend to backend hardwares

Frameworks to intermediate representation

NNVM: graph as high level IR

problem with computation graph: too many choices: precision layout fused pattern decices...

Hardware challenges for low level IR

More and more computation get tensorized

index based IR

(Algorithm described in IR, scheduling optimzation) -> lowring -> codegen

Separation of compilation and deployment

(framework front end -> NNVM -> TVM -> TVM graph module) -> deploy (JS java python)

Remote execution

Server weith TVM compiler  <- TVM RPC -> Devices with TVM runtime

End to end stack for deep learning systems

Frameworks -> NNVM -> Graph optimization -> TVM -> TVM primitives -> LLVM ...


## Takuya Akiba

ChainerMN

Chainer: A flexible deep learning framework
  In contrast to Define-and-run model, Chainer uses define-by-run model
  Benefit: able to reuse many python libraries

ChainerMN: distributed training with chainer
  near-linear scaling with hundreds of GPUs

Update 1: + MPI
Update 2: backpropagatable send recv functions
  Model parallelism

send func produces  a dummy empty variable
force to connect this dummmy to next recv func

## Jun Xu  EasyML

ease the process of meachine learning

applying machine learnign algorithms is hard due to the complex process of using the algorithms

Large scale machine learning system @ICT


## Sidhharsa Sen from Microsoft

Microsoft AI

Agent, applications, services, infrastructure

Today focuses on Services

Cognitive services

try them free

Decision service - contectual learning

A cloud based conextual decision making API  that shrpens with experience

Contextual
Rapid learning

Which article does a user want to read

MSN deployment
10s of millions of users

What is the decision service?
an interactive learning platform for contextual decisions
contextual bandit learning: right framework for many apps
 exploration

Classic randomized experiment: online AB test
 randomizing over policies

Bottleneck: feature/reward engineering
feature engineering is hard: automate it
reward engineering is hard:

## Bryan Catanzaro, from NVidea

The graph that shows the deep learning gradually beats all other types of machine learning methods

CUDA: most ppl working on deep learning  dont have to know about cuda
C++ for accelerated processors
onchip memory managemnt
asynchronous parallel API

CUDA libraries
CUBLAS
CUDNN

Communication libraries
NCCL, MPI

Frameworks
Cambrian explosion of AI
Lots of AI frameworks

Simulation
thinking about future, simulation will be impoartant given agents interact with the real world.  We have to do it in simulation. Playing video game, we are simulating the real world.
Project Issac, simulator for RL

Deep neural networks
u_j = f (\sum (w_ij x_i))   --- one layer

traning one model : 20+ exaflops
computation dominated by dot products

Scale matters
MOre data more compute means more AI

Successful AI uses accelerated computing
More specialization 20x in 10 years

V100 GPU
21B transistors, 821 mm^2
80 SM, 5120 cores 640 tensor cores

mixed precision for training
Lower precision integer for inference

Tensor core
chunky matrix multiply

Volta NVlink
300GB/sec/processor

## Matei Zaharia

DAWN infrastructrue for usable machine learning

Gold age of data

Huege effort in data prep model tuning experimentation and productionizing

Not main focus of either ML or systems research

Tiny part spent on ML code in the entire software development life cycle

It's happened before: Search
any developer can add search to an application
encapsulated complexity

It's happened before: SQL
SQL forms basis for transacitonal engines, data warhousing and business intelligence

Key idea:
end to end systems that tackles the barriers to access and production

The DAWN Stack

Example: MacroBAse for continuous analytics
multi dimensional data streams -> MacroBase -> anomalies and explanations

too much data for manual inspection, even harder when streaming

Snorkel:

training data is key enabler of machine learning
training data is key barrier to entry
If data is new oil, then training is the new new oil

How can we leverage data that's expensive to label at scale?

Snorkel's approach: weak supervision
Labeling functions: short programs that may not always give right label
snorkel simultaneously learns noise in LFs and noise aware target model

whats the interface between human and machine learning systems:

NoScope: fast CNN based video queries
challege: processig 1 video in real time requires a $1000 GPU
Key ideas in noscope:
model specialization
  given a garget model and a query train a much smaller specialized model
  when small model is unsure call original

Specialized difference detectors

End to end compilers for modern hardwares: Weld
As you compose library you introduce inefficiency.
for data intensive apps, data movement cost dominates

Weld's approach: Weld IR
(SQL, ML ...) -> weld IR -> ...

# SOSP main conference

## Jonathan Kaldor from Facebook, Canopy: end to end Performance tracing and analysis system

Brower makes requests to server. web server make responses to clients. Web servers make request s to other servers

Performance got worse
how long did the page load take?

aggregation over many traces
map trace concepts to database types

Canopy

instrumentation events -> modeled trace -> extracted features -> data tables

features: computed values from a single trace

-> filter1  -> feature1 -> tableB

developers can choose what and how to represent performnce information and structure

execution models can change

updating cross-system instrumentation

backend considerations
when is a trace ready to have features extracted?
multiple domains == multiple tenants isolation?

case study: causal ordering
case study: mobile client regression

limitations:
Traceid propagation assumes a single starting point
features need to map tot database column types
features a still manually specified

Summmary
Analyze 1B traces per day
Canopy converts traces to actionable information

## Algorand

## Srivasta, MIT, file system for multicore systems

(a lot of audience questioning)

Benchmark : dbench

concurrent access contends on directory block
contention on blocks blimits scalability on 80 cores
even apps not limited by disk IO dont scale

Commutative operations can be implimted without cache line conflicts

How do we scale all commutative operations in file systems ?

ScaleFS: Two separate file systems
MemFS and DiskFS

In memFS, directories as hash tables designed for multicore scalability

MemFS fsyncs to DiskFS

Design for fsync:
 per core oeraton logs to scalably defer updates to DiskFS
 Ordering operations using time stamp counters

How to order operations in per core operation logs?
how to operate Memfs and diskfs independently

Problem: preserving oredering of noncommuative ops

example: unlink file1 on core1,  create file1 on core 2
solution: use synchronized time stamp counters
rdtscp does not incur cacheline conflicts

at fsync, sort the ops by timestamps

Problem: how to allocate inodes scalably in MemFS?
Solution1: separate mnodes in MemFS from inodes in DiskFS
Solution2:

Implementation
on the sv6 research operating system

## Qi Huang, SVE distributed video processing at facebook scale

(intensive engineering)

FB: 500M users watch 100M hours video daily
Instgram: 250M daily active users for stories

Processing is diverse and demanding

Part 1: lagacy system

upload video file to webserver
client -> web server -> original storage -> processing -> final storage

focus: pre sharing pipeline
monolithic script slows development

challenges for video processing at FB
speedy:
flexible: thousands of engineers can write piplines for tens of apps
robust:

Speedy: harness parallelism
Overlap fault tolerance and processing
overlap upload and processing
parallel processing with many workers

Flexible: build DAG framework
DAG of computation on the stream-of-tracks abstraction

input video -> (images track, sound track, metadata track)

Robust: tolerate overload
rely on priority to degrade non-latency sensitive tasks

3x peak load on NYE

Use priority for worker overload
Scheduler -> Hi priority queue, Lo priority queue
Defer full video processing

## Jialin Li, Eris Coordination free consistent transactions using in netowrk concurrency

Data partitioned for scalability
replicated for availability

Eris

Processes independent transactions
without coordination int the normal case

performance within 3% of a nontransactional unreplicated system
strong consistent

leveraging the datacenter network

traditional layered approach

atomic commitment(2PC)

in network concurrency control goals
globally consistencyordering across messages

Multi-sequenced groupcast

groupcast: message header specifies a set of destination multicast groups
multi-sequenced groupcast:

groupcast routing using openflow
programmable switches written in P4
middlebox prototype using network processors


Transaction model

two types of transactions
 on shot
 no cross shard dependencies
 proposed by HStore


Eris protocol

normal case:
client issues requests to sequencer which then forwards the requests to shards.

how does Eris handle dropped messages?
introduce a new central failure coordinator

Eris uses view change protocols

related works:
NOPaxos

## Xin Jin, NetCache

rack-scale key value store

target workloads
small objects
read intensive
high skewed and dynamic key popularity

challenge:
low throughput and high tail latency
how to provide effective dynamic load balancing?

Opportunity: fast, small cache can ensure load balancing
Cache O(NlogN) hottest items

caching in network switch

key value caching in network asic at line rate?
how to identify application level packet field?
how to store and serve variable length data
how to to efficently keep the cache up to date?

PISA Protocol independent switch architecture

Programmable Parser
Programmable match action pipeline


## Bojie Li, KV-direct high performance in memory key value store

Goal: accelerate key value store performance in data center scale

key value store architectures:
software - kernel tcp/ip
       kernel by-passing
       onesided rdma


NIC -> Network decoder -> request scheduler
                                 |

## BoF session on democratizing AI
Panel members: Matei Zaharia, Joseph Gonzalez, Garth Gibson, Alex Smola

Matei:
factors that challenge applying AI techniques by ordinary people
1) A great deal of unlabeled data
2) huge amount of money needed 

Joseph:
security,
reinforcement learning, use AI in making decisions
system research in AI is maturing
can we get linear scaling in GPU
trend in AI community, layering
training is not the only interesting part in machine learning, more effort should be invested in inference

Garth:
commenting on overfitting

Alex:
there isnt only one way to make AI available to customers
need a full range of products





# Take home messages


