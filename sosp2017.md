## Eric Xing 

Data-parallel proximal gradient under SSP

in the past, BSP model

A statle synchronous parallel bridgiing model

Parameter server architecture
 - Bosen

SSP data parallel convergence theorem

SSP Data parallel, Async performance

System / Algorithm codesign

Matrix parameterized models

Big MPMs

Need to send paralllel worker updates to other machines
 Primal SGC
 Stochastic dual coordinate ascent

A computing communication tradeoff

 Full update
 pre-update

Why is SFB faster?
 Faster than PS and Spark

Topologies to use

Paramster storage and communication paradigms

Synchonization of a paramter machines

How t o reduce traffic in P2P
  random partial broadcasting

Hybrid updates: PS + SFB
 Example : CNN

 How to distribute?
 How to communicate?


## Paul Barham

Programming model
Hardware paltforms
Model architectures
machine learning inside the system

Use machine learning to improve machine learning system itself

Tensorflow: distributed dataflow ()with state)

Programming model evolution

Note to system people: faster isnt always better

Eager graphs and compilation ....
 Eager execution: increased interactivity
 graph model: flexible distributed computation
 JIT compiler: acceleration of important subgraphs
 Ahead of time compilation: generate standalone binaries

A few trends in the kinds of mdoels we want to train

deepmind wavenet

recurrent sequence model

very large language models needing model parallelism

Bigger model, but sparsely activated 

huge model capacity for large

strucutre for the model: repeated structure

For large models, model parallelism is important

Using reinforcement learning to imporve system performance

replace complex heuristics with leared strategies
 compiler optimzations
 placement of operators on devices

Device placement with reinforcement learning

Using reinforcement learning to design the model

Current solution = data + computation + ML experties
Can we turn this into solution = date + 100x computation

Idea : model-generating model trained via RL (ICLR 2017)
  generate ten models
  train them on the same problem for a fixed time

Conclusions
 After 30 uears and 10^5 x compute neural networks alaready outperform hunmans on many tasks
 Machine learning systems are rapidly evolving
   researchers driving changes to programmingmodel
   exciting hardware

## Joseph Gonzalez

Research at the interaction of AI and systems

Look back:
 Scaling to large datasets
 Using machine learning to solve problems in system
 Big learning

 support lowlatency high through put serving workloads

 models getting more complex
 10x of Gflops
 recurrentnets

 deployed on critical path

 hardware in the train domain



## Tianqi Chen

Layout transormation
Quantization
operator kernal optimzation
benchmarking

need optimzed hardware kernel for each variable and each hardware 

One problem to solve, to bridge frontend to backend hardwares

Frameworks to intermediate representation

NNVM: graph as high level IR

problem with computation graph: too many choices: precision layout fused pattern decices...

Hardware challenges for low level IR

More and more computation get tensorized

index based IR

(Algorithm described in IR, scheduling optimzation) -> lowring -> codegen

Separation of compilation and deployment

(framework front end -> NNVM -> TVM -> TVM graph module) -> deploy (JS java python)

Remote execution

Server weith TVM compiler  <- TVM RPC -> Devices with TVM runtime

End to end stack for deep learning systems

Frameworks -> NNVM -> Graph optimization -> TVM -> TVM primitives -> LLVM ...


## Takuya Akiba

ChainerMN

Chainer: A flexible deep learning framework
  In contrast to Define-and-run model, Chainer uses define-by-run model
  Benefit: able to reuse many python libraries

ChainerMN: distributed training with chainer
  near-linear scaling with hundreds of GPUs

Update 1: + MPI
Update 2: backpropagatable send recv functions
  Model parallelism

send func produces  a dummy empty variable
force to connect this dummmy to next recv func

## Jun Xu  EasyML

ease the process of meachine learning

applying machine learnign algorithms is hard due to the complex process of using the algorithms

Large scale machine learning system @ICT


## Sidhharsa Sen from Microsoft

Microsoft AI

Agent, applications, services, infrastructure

Today focuses on Services

Cognitive services

try them free

Decision service - contectual learning

A cloud based conextual decision making API  that shrpens with experience

Contextual
Rapid learning

Which article does a user want to read

MSN deployment
10s of millions of users

What is the decision service?
an interactive learning platform for contextual decisions
contextual bandit learning: right framework for many apps
 exploration

Classic randomized experiment: online AB test
 randomizing over policies

Bottleneck: feature/reward engineering
feature engineering is hard: automate it
reward engineering is hard:

## Bryan Catanzaro, from NVidea

The graph that shows the deep learning gradually beats all other types of machine learning methods

CUDA: most ppl working on deep learning  dont have to know about cuda
C++ for accelerated processors
onchip memory managemnt
asynchronous parallel API

CUDA libraries
CUBLAS
CUDNN

Communication libraries
NCCL, MPI

Frameworks
Cambrian explosion of AI
Lots of AI frameworks

Simulation
thinking about future, simulation will be impoartant given agents interact with the real world.  We have to do it in simulation. Playing video game, we are simulating the real world.
Project Issac, simulator for RL

Deep neural networks
u_j = f (\sum (w_ij x_i))   --- one layer

traning one model : 20+ exaflops
computation dominated by dot products

Scale matters
MOre data more compute means more AI

Successful AI uses accelerated computing
More specialization 20x in 10 years

V100 GPU
21B transistors, 821 mm^2
80 SM, 5120 cores 640 tensor cores

mixed precision for training
Lower precision integer for inference

Tensor core
chunky matrix multiply

Volta NVlink
300GB/sec/processor

## Matei Zaharia

DAWN infrastructrue for usable machine learning

Gold age of data

Huege effort in data prep model tuning experimentation and productionizing

Not main focus of either ML or systems research

Tiny part spent on ML code in the entire software development life cycle

It's happened before: Search
any developer can add search to an application
encapsulated complexity

It's happened before: SQL
SQL forms basis for transacitonal engines, data warhousing and business intelligence

Key idea:
end to end systems that tackles the barriers to access and production

The DAWN Stack

Example: MacroBAse for continuous analytics
multi dimensional data streams -> MacroBase -> anomalies and explanations

too much data for manual inspection, even harder when streaming

Snorkel:

training data is key enabler of machine learning
training data is key barrier to entry
If data is new oil, then training is the new new oil

How can we leverage data that's expensive to label at scale?

Snorkel's approach: weak supervision
Labeling functions: short programs that may not always give right label
snorkel simultaneously learns noise in LFs and noise aware target model

whats the interface between human and machine learning systems:

NoScope: fast CNN based video queries
challege: processig 1 video in real time requires a $1000 GPU
Key ideas in noscope:
model specialization
  given a garget model and a query train a much smaller specialized model
  when small model is unsure call original

Specialized difference detectors

End to end compilers for modern hardwares: Weld
As you compose library you introduce inefficiency.
for data intensive apps, data movement cost dominates

Weld's approach: Weld IR
(SQL, ML ...) -> weld IR -> ...

